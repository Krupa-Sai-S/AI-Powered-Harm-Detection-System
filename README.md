# AI-Powered Harm Detection System

## ğŸš€ Overview
This project is an **AI-powered NLP system** that detects harmful content in **text, URLs, and QR codes**. It uses **Machine Learning (XGBoost) with TF-IDF vectorization** to classify inputs into categories: **Hate Speech, Offensive, or Neutral**.

## ğŸ”¥ Features
- **ğŸ§  AI-Based Harm Detection** - Uses ML to classify harmful content.
- **ğŸ”— URL Analysis** - Extracts and analyzes webpage text.
- **ğŸ“· QR Code Scanner** - Extracts links from QR codes and checks them.
- **ğŸ“Š Analytics Dashboard** - Tracks history, visualizations, and trends.
- **ğŸ“„ PDF Report Generator** - Exports a session report.
- **ğŸ” Secure Login** - User-based tracking.

## ğŸ›  Tech Stack
- **Frontend**: Streamlit
- **Machine Learning**: XGBoost (Trained with TF-IDF)
- **Backend**: Python
- **Libraries**:
  - `scikit-learn`, `xgboost`: Model training & evaluation
  - `pickle`: Model storage
  - `requests`, `BeautifulSoup`: Web scraping
  - `opencv-python`, `pyzbar`: QR code scanning
  - `matplotlib`, `wordcloud`: Data visualization
  - `fpdf`: PDF generation

## ğŸ“ Repository Structure
```
AI-Harm-Detection/
â”‚â”€â”€ models/               # Trained ML models (model.pkl, vectorizer.pkl)
â”‚â”€â”€ data/                 # Dataset samples (train/test)
â”‚â”€â”€ notebooks/            # Jupyter notebooks for training & evaluation
â”‚â”€â”€ scripts/              # Preprocessing & training scripts
â”‚â”€â”€ app.py                # Main Streamlit app
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation
â”‚â”€â”€ config.yaml            # Configuration settings
â”‚â”€â”€ docs/                  # Additional documentation
â”‚â”€â”€ tests/                 # Unit tests for API and ML model
```

## ğŸ¯ Dataset & Model Training
- **Dataset**: Hate Speech and Offensive Language Dataset (Kaggle)
- **Preprocessing**:
  - Text Cleaning (Removing stopwords, punctuation, lowercasing)
  - TF-IDF Vectorization
- **Model Used**: XGBoost (Optimized for high accuracy)


## âš¡ Installation
### Prerequisites
Ensure you have **Python 3.8+** installed.

### Step 1: Clone the Repository
```bash
git clone https://github.com/Krupa-Sai-S/AI-Harm-Detection.git
cd AI-Harm-Detection
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Run the Application
```bash
streamlit run app.py
```

## ğŸ¯ How to Use
1. **Login** with your credentials.
2. **Select an action:**
   - **Detector**: Analyze text for harmful content.
   - **URL Check**: Enter a URL and analyze its content.
   - **QR Code Scanner**: Upload a QR image and check its embedded link.
   - **Analytics**: View label distribution and trends.
   - **Report**: Download a PDF of your session history.
3. **Logout** when finished.



## ğŸ‘¨â€ğŸ’» Contributors
- **Krupa Sai Sammangi**
- **Karthik pilli**

## ğŸ“œ License
This project is licensed under the MIT License.

## ğŸ“© Contact
For inquiries, reach out to **Krupa Sai Sammangi**.

---
### Notes:
- Ensure `model.pkl` and `vectorizer.pkl` are available in `models/`.
- If using a different ML model, update `load_model()` accordingly.
- Future improvements: Upgrade model to **BERT** for even higher accuracy.

